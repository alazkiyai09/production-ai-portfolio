# ===========================================
# LLM Provider API Keys
# ===========================================
OPENAI_API_KEY=sk-your-openai-key-here
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
COHERE_API_KEY=your-cohere-key-here
HUGGINGFACE_API_KEY=your-huggingface-key-here

# ===========================================
# Model Configuration
# ===========================================
# Default models to evaluate
DEFAULT_OPENAI_MODEL=gpt-4-turbo-preview
DEFAULT_ANTHROPIC_MODEL=claude-3-opus-20240229
DEFAULT_COHERE_MODEL=command
DEFAULT_LOCAL_MODEL_PATH=/path/to/local/model

# ===========================================
# Evaluation Settings
# ===========================================
# Maximum concurrent evaluations
MAX_CONCURRENT_EVALUATIONS=10

# Request timeout in seconds
REQUEST_TIMEOUT=120

# Maximum retries for failed requests
MAX_RETRIES=3

# Retry backoff multiplier
RETRY_MULTIPLIER=2

# ===========================================
# Judge Model Configuration
# ===========================================
# Model used for LLM-as-judge evaluations
JUDGE_MODEL_PROVIDER=openai
JUDGE_MODEL_NAME=gpt-4-turbo-preview

# ===========================================
# Evaluation Metrics
# ===========================================
# Enable/disable specific metrics
ENABLE_ACCURACY_METRICS=true
ENABLE_LATENCY_METRICS=true
ENABLE_COST_METRICS=true
ENABLE_HALLUCINATION_METRICS=true
ENABLE_SAFETY_METRICS=true
ENABLE_FORMAT_COMPLIANCE_METRICS=true

# Semantic similarity threshold (0-1)
SEMANTIC_SIMILARITY_THRESHOLD=0.8

# ===========================================
# Paths
# ===========================================
# Base directory for data storage
DATA_DIR=./data

# Directory for datasets
DATASETS_DIR=./data/datasets

# Directory for evaluation results
RESULTS_DIR=./data/results

# Directory for cached model outputs
CACHE_DIR=./data/cache

# Directory for local models
LOCAL_MODELS_DIR=./data/models

# ===========================================
# API Configuration
# ===========================================
# FastAPI host and port
API_HOST=0.0.0.0
API_PORT=8000

# CORS origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:8501

# API key for authentication (optional)
API_KEY=

# Maximum request body size in MB
MAX_REQUEST_SIZE=10

# ===========================================
# Dashboard Configuration
# ===========================================
# Streamlit host and port
DASHBOARD_HOST=0.0.0.0
DASHBOARD_PORT=8501

# ===========================================
# Monitoring & Observability
# ===========================================
# Prometheus metrics port
METRICS_PORT=9090

# Enable Prometheus metrics
ENABLE_METRICS=true

# Metrics path endpoint
METRICS_ENDPOINT=/metrics

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Log file path (empty for stdout only)
LOG_FILE=

# ===========================================
# Database (Optional, for results persistence)
# ===========================================
# PostgreSQL connection string
# DATABASE_URL=postgresql://user:password@localhost:5432/llmops_eval

# SQLite fallback (default)
SQLITE_DB_PATH=./data/results.db

# ===========================================
# Rate Limiting
# ===========================================
# Requests per minute per API key
RATE_LIMIT_RPM=60

# Concurrent requests per user
MAX_CONCURRENT_REQUESTS=5

# ===========================================
# Feature Flags
# ===========================================
# Enable caching of model responses
ENABLE_CACHE=true

# Cache TTL in seconds
CACHE_TTL=3600

# Enable async evaluation
ENABLE_ASYNC=true

# Enable detailed logging
ENABLE_DEBUG_LOGGING=false

# ===========================================
# Security
# ===========================================
# Secret key for session encryption
SECRET_KEY=your-secret-key-here

# Enable HTTPS (production)
ENABLE_HTTPS=false

# SSL certificate path
SSL_CERT_PATH=

# SSL key path
SSL_KEY_PATH=
