# ============================================================
# Enterprise-RAG: Environment Variables Configuration
# ============================================================
# Copy this file to .env and fill in your values
# NEVER commit .env to version control

# =====================
# API Keys
# =====================
# OpenAI API Key for LLM and RAGAS evaluation
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic API Key (optional, for Claude models)
# Get from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# Cohere API Key (optional, for Cohere reranker)
# Get from: https://dashboard.cohere.com/api-keys
COHERE_API_KEY=your-cohere-api-key-here

# =====================
# Model Configuration
# =====================
# Embedding model for vector generation
# Options: all-MiniLM-L6-v2, all-mpnet-base-v2, e5-large-v2
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Reranking model for cross-encoder reranking
# Options: cross-encoder/ms-marco-MiniLM-L-6-v2, cross-encoder/ms-marco-MiniLM-L-12-v2
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# LLM for response generation
# Options: gpt-4, gpt-4-turbo, gpt-3.5-turbo, claude-3-opus-20240229
LLM_MODEL=gpt-4-turbo
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=1024

# =====================
# Chunking Configuration
# =====================
# Size of text chunks for embedding (in characters)
CHUNK_SIZE=512

# Overlap between consecutive chunks (in characters)
CHUNK_OVERLAP=50

# =====================
# Retrieval Configuration
# =====================
# Number of chunks to retrieve from vector store
TOP_K_RETRIEVAL=10

# Number of chunks to return after reranking
TOP_K_RERANK=5

# Whether to enable BM25 sparse retrieval
ENABLE_BM25=true

# BM25 k1 parameter (term frequency saturation)
BM25_K1=1.5

# BM25 b parameter (length normalization)
BM25_B=0.75

# =====================
# Vector Database
# =====================
# Vector store type: chroma or qdrant
VECTOR_STORE_TYPE=chroma

# ChromaDB persistence path (relative to project root)
CHROMA_PATH=./data/chroma

# Qdrant configuration (if using Qdrant)
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_GRPC_PORT=6334
QDRANT_COLLECTION_NAME=enterprise_rag
QDRANT_API_KEY=

# =====================
# Document Processing
# =====================
# Maximum file size for upload (in MB)
MAX_FILE_SIZE=50

# Supported document formats (comma-separated)
SUPPORTED_FORMATS=pdf,docx,md,txt

# Path to store uploaded documents
DOCUMENTS_PATH=./data/documents

# =====================
# API Configuration
# =====================
# FastAPI host and port
API_HOST=0.0.0.0
API_PORT=8000

# Enable CORS for frontend
CORS_ORIGINS=http://localhost:8501,http://localhost:3000

# API request timeout (in seconds)
API_TIMEOUT=300

# =====================
# Logging Configuration
# =====================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log file path
LOG_FILE=./logs/enterprise_rag.log

# Enable console logging
CONSOLE_LOGGING=true

# Log format: json or text
LOG_FORMAT=text

# =====================
# Evaluation Configuration
# =====================
# Enable RAGAS evaluation
ENABLE_EVALUATION=true

# RAGAS evaluation metrics (comma-separated)
# Options: faithfulness, answer_relevancy, context_recall, context_precision
EVALUATION_METRICS=faithfulness,answer_relevancy,context_recall

# Number of samples for evaluation
EVALUATION_SAMPLE_SIZE=50

# =====================
# Performance Configuration
# =====================
# Number of workers for document processing
WORKER_COUNT=4

# Batch size for embedding generation
EMBEDDING_BATCH_SIZE=32

# Enable GPU for embeddings (if available)
ENABLE_GPU=false

# Cache embeddings to disk
CACHE_EMBEDDINGS=true

# =====================
# Security
# =====================
# Secret key for JWT tokens (generate with: python -c "import secrets; print(secrets.token_urlsafe(32))")
SECRET_KEY=your-secret-key-change-this-in-production

# Token expiration time (in hours)
TOKEN_EXPIRATION_HOURS=24

# =====================
# Feature Flags
# =====================
# Enable query caching
ENABLE_QUERY_CACHE=true

# Enable streaming responses
ENABLE_STREAMING=true

# Enable hybrid search (dense + sparse)
ENABLE_HYBRID_SEARCH=true
