"""
AIGuard - Security Guardrails for LLM Applications

Protects against prompt injection, jailbreaking, PII leakage, and encoding attacks.
"""

__version__ = "0.1.0"
__author__ = "Your Name"
